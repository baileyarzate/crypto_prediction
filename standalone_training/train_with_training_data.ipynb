{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0663747b",
   "metadata": {},
   "source": [
    "## This script is meant for trying new ML methods on the same data, adjusting features, and experimentation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0095766d",
   "metadata": {},
   "source": [
    "Deep learning architectures such as LSTM, Transformer-based models, and Prophet were also evaluated.\n",
    "However, their performance (MAE ~ 40,000) was significantly worse than classical regression approaches.\n",
    "This is primarily due to the limited data available at daily frequency and the weak temporal dependencies in Bitcoinâ€™s daily closing prices.\n",
    "Simpler models like Linear and Ridge Regression performed best, suggesting that the signal is mostly short-memory and linear in nature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48baaf2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Performing Feature Engineering ---\n",
      "--- Training and Evaluating Models ---\n",
      "\n",
      "--- Residual Correction with XGBoost ---\n",
      "\n",
      "--- Model Performance on Test Set ---\n",
      "                    Model          MAE\n",
      "1  Ridge Regression (0.5)  1513.408994\n",
      "0       Linear Regression  1531.126675\n",
      "4   LR + Residual XGBoost  2818.299613\n",
      "2           Random Forest  8628.666786\n",
      "3                 XGBoost  9582.581327\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "import xgboost as xgb\n",
    "#from statsmodels.tsa.arima.model import ARIMA\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "def calculate_rsi(data, window=14):\n",
    "    delta = data['close'].diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()\n",
    "    rs = gain / loss.replace(0, 1e-6)\n",
    "    return 100 - (100 / (1 + rs))\n",
    "\n",
    "# --- Feature Engineering ---\n",
    "def feature_engineering(df):\n",
    "    print(\"--- Performing Feature Engineering ---\")\n",
    "    if len(df) < 15:\n",
    "        raise ValueError(f\"Dataframe size too small ({len(df)} rows).\")\n",
    "\n",
    "    df_feat = df.copy()\n",
    "\n",
    "    # Core technicals\n",
    "    df_feat['rsi_14'] = calculate_rsi(df_feat, window=14)\n",
    "    df_feat['lag_1'] = df_feat['close'].shift(1)\n",
    "    df_feat['lag_5'] = df_feat['close'].shift(5)\n",
    "    df_feat['lag_10'] = df_feat['close'].shift(10)\n",
    "    df_feat['rolling_mean_5'] = df_feat['close'].rolling(window=5).mean()\n",
    "    df_feat['rolling_std_5'] = df_feat['close'].rolling(window=5).std()\n",
    "    df_feat['rolling_mean_10'] = df_feat['close'].rolling(window=10).mean()\n",
    "    df_feat['rolling_std_10'] = df_feat['close'].rolling(window=10).std()\n",
    "\n",
    "    # Log return volatility / momentum\n",
    "    log_return = np.log(df_feat['close'] / df_feat['close'].shift(1))\n",
    "    df_feat['volatility_7'] = log_return.rolling(window=7).std()\n",
    "    df_feat['momentum_5'] = log_return.rolling(window=5).mean()\n",
    "\n",
    "    # Derived interaction features\n",
    "    df_feat['high_low_spread'] = df_feat['high'] - df_feat['low']\n",
    "    df_feat['momentum_x_volume'] = df_feat['momentum_5'] * df_feat['volume']\n",
    "    df_feat['rsi_sq'] = df_feat['rsi_14'] ** 2\n",
    "    df_feat['volatility_7_sq'] = df_feat['volatility_7'] ** 2\n",
    "\n",
    "    # Delta / deviation features\n",
    "    df_feat['close_delta_5'] = df_feat['close'] - df_feat['close'].shift(5)\n",
    "    df_feat['log_return_abs'] = np.abs(log_return)\n",
    "    df_feat['high_low_vol_ratio'] = df_feat['high_low_spread'] / (df_feat['rolling_std_10'] + 1e-6)\n",
    "\n",
    "    # Adaptive rolling signals (EWMA)\n",
    "    df_feat['ewma_5'] = df_feat['close'].ewm(span=5, adjust=False).mean()\n",
    "    df_feat['ewma_10'] = df_feat['close'].ewm(span=10, adjust=False).mean()\n",
    "    df_feat['ewma_ratio'] = df_feat['ewma_5'] / (df_feat['ewma_10'] + 1e-6)\n",
    "\n",
    "    # Day of week effect\n",
    "    df_feat['day_of_week'] = df_feat['merge_date'].dt.dayofweek\n",
    "\n",
    "    return df_feat\n",
    "\n",
    "df = pd.read_csv(r'C:\\Users\\baile\\Documents\\Artificial Intelligence\\BitcoinPred\\standalone_training\\bitcoin_sentiment_12012022_11082025.csv')\n",
    "df['target'] = df['close'].shift(-1)\n",
    "df['merge_date'] = pd.to_datetime(df['merge_date'], errors='coerce')\n",
    "df = feature_engineering(df)\n",
    "\n",
    "# --- Define and Clean ---\n",
    "features = [col for col in df.columns if col not in ['merge_date', 'datetime_utc', 'timestamp', 'target'] and 'unnamed' not in col]\n",
    "required_cols = features + ['target']\n",
    "data_clean = df.dropna(subset=required_cols).reset_index(drop=True)\n",
    "if data_clean.empty:\n",
    "    raise ValueError(\"Empty after cleaning. Check for NaN-heavy feature creation.\")\n",
    "\n",
    "X = data_clean[features]\n",
    "y = data_clean['target'] # Use the new 'target' column\n",
    "\n",
    "# --- 3. Split and Train ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "selected_features = [\n",
    "    'open', 'high', 'low', 'close', 'volume', 'weighted_sentiment',\n",
    "    'lag_1', 'lag_5', 'lag_10', 'rolling_mean_5', 'rolling_mean_10',\n",
    "    'rolling_std_10', 'volatility_7', 'volatility_7_sq',\n",
    "    'momentum_5', 'momentum_x_volume', 'rsi_sq', 'close_delta_5',\n",
    "    'ewma_ratio', 'high_low_spread', 'high_low_vol_ratio', 'day_of_week'\n",
    "]\n",
    "\n",
    "X_train = X_train[selected_features]   \n",
    "X_test = X_test[selected_features]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "########################\n",
    "\n",
    "print(\"--- Training and Evaluating Models ---\")\n",
    "results = {}\n",
    "\n",
    "\n",
    "# 4. Train ML Models\n",
    "mlr_model = LinearRegression().fit(X_train_scaled, y_train)\n",
    "ridge_model = Ridge(alpha=0.5, random_state=42).fit(X_train_scaled, y_train)\n",
    "rf_model = RandomForestRegressor(n_estimators=600, random_state=42).fit(X_train_scaled, y_train)\n",
    "xgb_model = xgb.XGBRegressor(colsample_bytree=1.0, learning_rate=0.03, max_depth= 7,n_estimators=1200, subsample = 0.9,\n",
    "                             objective='reg:squarederror', random_state=42).fit(X_train_scaled, y_train)\n",
    "\n",
    "# Train Auto-ARIMA on the training data for a fair comparison\n",
    "#arima_model = ARIMA(y_train, order=(1,1,3))\n",
    "#arima_model_fit = arima_model.fit()\n",
    "\n",
    "# Evaluate Models\n",
    "mlr_preds = mlr_model.predict(X_test_scaled)\n",
    "ridge_preds = ridge_model.predict(X_test_scaled)\n",
    "rf_preds = rf_model.predict(X_test_scaled)\n",
    "xgb_preds = xgb_model.predict(X_test_scaled)\n",
    "#arima_preds = arima_model_fit.forecast(steps=len(y_test))\n",
    "# --- Residual Correction using XGBoost ---\n",
    "print(\"\\n--- Residual Correction with XGBoost ---\")\n",
    "linear_residuals = y_train - mlr_model.predict(X_train_scaled)\n",
    "residual_model = xgb.XGBRegressor(\n",
    "    learning_rate=0.03, max_depth=7, n_estimators=800, subsample=0.9,\n",
    "    colsample_bytree=0.9, objective='reg:squarederror', random_state=42\n",
    ")\n",
    "residual_model.fit(X_train_scaled, linear_residuals)\n",
    "residual_corrections = residual_model.predict(X_test_scaled)\n",
    "ridge_corrected_preds = mlr_preds + residual_corrections\n",
    "\n",
    "\n",
    "# --- Evaluation ---\n",
    "results = {\n",
    "    'Linear Regression': mean_absolute_error(y_test, mlr_preds),\n",
    "    'Ridge Regression (0.5)': mean_absolute_error(y_test, ridge_preds),\n",
    "    'Random Forest': mean_absolute_error(y_test, rf_preds),\n",
    "    'XGBoost': mean_absolute_error(y_test, xgb_preds),\n",
    "    'LR + Residual XGBoost': mean_absolute_error(y_test, ridge_corrected_preds)\n",
    "}\n",
    "\n",
    "results_df = pd.DataFrame(results.items(), columns=['Model', 'MAE']).sort_values(by='MAE')\n",
    "print(\"\\n--- Model Performance on Test Set ---\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774b025a",
   "metadata": {},
   "source": [
    "### This block of code is for calling the training function in the main_scripts folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75ff33ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-12 17:02:00,386 - INFO - -------------------------------------\n",
      "2025-11-12 17:02:00,386 - INFO - \n",
      "Selected Features used for Training: ['open', 'high', 'low', 'close', 'volume', 'weighted_sentiment', 'lag_1', 'lag_5', 'lag_10', 'rolling_mean_5', 'rolling_mean_10', 'rolling_std_10', 'volatility_7', 'volatility_7_sq', 'momentum_5', 'momentum_x_volume', 'rsi_sq', 'close_delta_5', 'ewma_ratio', 'high_low_spread', 'high_low_vol_ratio', 'day_of_week']\n",
      "2025-11-12 17:02:00,403 - INFO - Model: Linear Regression, Hyperparameters: {}\n",
      "2025-11-12 17:02:00,403 - INFO - Model: Ridge Regression (0.5), Hyperparameters: {'alpha': 0.5}\n",
      "2025-11-12 17:02:00,403 - INFO - Model: Random Forest, Hyperparameters: {'n_estimators': 600, 'random_state': 42}\n",
      "2025-11-12 17:02:00,403 - INFO - Model: XGBoost, Hyperparameters: {'colsample_bytree': 1.0, 'learning_rate': 0.03, 'max_depth': 7, 'n_estimators': 1200, 'subsample': 0.9}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Performing Feature Engineering ---\n",
      "--- Preparing Data for True Forecasting ---\n",
      "--- Training and Evaluating Models ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-12 17:02:30,403 - INFO - |                        |     MAE |\n",
      "|:-----------------------|--------:|\n",
      "| Ridge Regression (0.5) | 1513.41 |\n",
      "| Linear Regression      | 1531.13 |\n",
      "| Random Forest          | 8628.67 |\n",
      "| XGBoost                | 9582.58 |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Model Performance on Test Set ---\n",
      "                                MAE\n",
      "Ridge Regression (0.5)  1513.408994\n",
      "Linear Regression       1531.126675\n",
      "Random Forest           8628.666786\n",
      "XGBoost                 9582.581327\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "sys.path.append(r'C:\\Users\\baile\\Documents\\Artificial Intelligence\\BitcoinPred')\n",
    "from main_scripts.train import train_and_evaluate\n",
    "# --- Feature Engineering ---\n",
    "\n",
    "def calculate_rsi(data, window=14):\n",
    "    delta = data['close'].diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()\n",
    "    rs = gain / loss.replace(0, 1e-6)\n",
    "    return 100 - (100 / (1 + rs))\n",
    "def feature_engineering(df):\n",
    "    print(\"--- Performing Feature Engineering ---\")\n",
    "    if len(df) < 15:\n",
    "        raise ValueError(f\"Dataframe size too small ({len(df)} rows).\")\n",
    "\n",
    "    df_feat = df.copy()\n",
    "\n",
    "    # Core technicals\n",
    "    df_feat['rsi_14'] = calculate_rsi(df_feat, window=14)\n",
    "    df_feat['lag_1'] = df_feat['close'].shift(1)\n",
    "    df_feat['lag_5'] = df_feat['close'].shift(5)\n",
    "    df_feat['lag_10'] = df_feat['close'].shift(10)\n",
    "    df_feat['rolling_mean_5'] = df_feat['close'].rolling(window=5).mean()\n",
    "    df_feat['rolling_std_5'] = df_feat['close'].rolling(window=5).std()\n",
    "    df_feat['rolling_mean_10'] = df_feat['close'].rolling(window=10).mean()\n",
    "    df_feat['rolling_std_10'] = df_feat['close'].rolling(window=10).std()\n",
    "\n",
    "    # Log return volatility / momentum\n",
    "    log_return = np.log(df_feat['close'] / df_feat['close'].shift(1))\n",
    "    df_feat['volatility_7'] = log_return.rolling(window=7).std()\n",
    "    df_feat['momentum_5'] = log_return.rolling(window=5).mean()\n",
    "\n",
    "    # Derived interaction features\n",
    "    df_feat['high_low_spread'] = df_feat['high'] - df_feat['low']\n",
    "    df_feat['momentum_x_volume'] = df_feat['momentum_5'] * df_feat['volume']\n",
    "    df_feat['rsi_sq'] = df_feat['rsi_14'] ** 2\n",
    "    df_feat['volatility_7_sq'] = df_feat['volatility_7'] ** 2\n",
    "\n",
    "    # Delta / deviation features\n",
    "    df_feat['close_delta_5'] = df_feat['close'] - df_feat['close'].shift(5)\n",
    "    df_feat['log_return_abs'] = np.abs(log_return)\n",
    "    df_feat['high_low_vol_ratio'] = df_feat['high_low_spread'] / (df_feat['rolling_std_10'] + 1e-6)\n",
    "\n",
    "    # Adaptive rolling signals (EWMA)\n",
    "    df_feat['ewma_5'] = df_feat['close'].ewm(span=5, adjust=False).mean()\n",
    "    df_feat['ewma_10'] = df_feat['close'].ewm(span=10, adjust=False).mean()\n",
    "    df_feat['ewma_ratio'] = df_feat['ewma_5'] / (df_feat['ewma_10'] + 1e-6)\n",
    "\n",
    "    # Day of week effect\n",
    "    df_feat['day_of_week'] = df_feat['merge_date'].dt.dayofweek\n",
    "\n",
    "    return df_feat\n",
    "\n",
    "selected_features = [\n",
    "    'open', 'high', 'low', 'close', 'volume', 'weighted_sentiment',\n",
    "    'lag_1', 'lag_5', 'lag_10', 'rolling_mean_5', 'rolling_mean_10',\n",
    "    'rolling_std_10', 'volatility_7', 'volatility_7_sq',\n",
    "    'momentum_5', 'momentum_x_volume', 'rsi_sq', 'close_delta_5',\n",
    "    'ewma_ratio', 'high_low_spread', 'high_low_vol_ratio', 'day_of_week'\n",
    "]\n",
    "\n",
    "df = pd.read_csv(r'C:\\Users\\baile\\Documents\\Artificial Intelligence\\BitcoinPred\\standalone_training\\bitcoin_sentiment_12012022_11082025.csv')\n",
    "df['target'] = df['close'].shift(-1)\n",
    "df['merge_date'] = pd.to_datetime(df['merge_date'], errors='coerce')\n",
    "df = feature_engineering(df)\n",
    "train_and_evaluate(df, selected_features=selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc15a10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crypto_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
